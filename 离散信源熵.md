## 信源熵的基本定理和性质

### 最大离散熵定理

离散随机变量，等概时，$H$ 最大
$$
？
$$

### 扩展性

$$
\lim\limits_{\epsilon\rightarrow0}H_{n+1}[p(x_1),p(x_2),p(x_3),...,p(x_n)-\epsilon,p(x_{n})=\epsilon]=H_{n+1}[p(x_1),p(x_2),p(x_3),...,p(x_n)]
$$

### 确定性

$$
H(1,0)=H(1,0,0)=H(1,0,0,...,0)=0
$$

确知信源H=0

### 可加性

$$
H(XY)=H(X)+H(Y/X)\\
H(XY)=H(Y)+H(X/Y)
$$

特别地，当X、Y独立时
$$
H(XY)=H(X)+H(Y)
$$

### 极值性

1. 同最大熵增定理
2. 

$$
H_n[p(x_1),p(x_2),p(x_3),...,p(x_n)]\leq \sum^{n}_{i=1}-p(x_i)\log p(y_j)
$$

### 条件熵小于无条件熵

### 上凸性

$$
f[aX_1+(1-a)X_2]\geq af(X_1)+(1-a)f(X_2)
$$

### 唯一性

$$
H_{n+m-1}(p_1,p_2,...,,p_{n-1},q_1,q_2,...,q_m)=H_n+p_nH_m(?)
$$

## 熵函数的简写法

