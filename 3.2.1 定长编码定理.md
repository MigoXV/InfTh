[TOC]

# 3.2.1 定长编码定理

定长编码定理
- 描述
- 证明
  - **渐进等分割性**
    - 描述
    - 证明
    - 物理意义
    - 应用
- 物理意义
- 实际应用中的问题

---

例3.2：英文电报有 32 个符号 $(26+6)$, 即 $\mathrm{q}=32$, 若 $r=2, N=1$ (即对信源的逐个符号进行二元编码), 风ा:
$$
l \geq \log q=\log 32=5 \mathrm{Bit} / \text { 符号 }
$$
解释：每个英文电报符号至少需要用 5 位二元符号编码
问题: 在考虑符号出现的概率和符号间相关性前提下, 每个英 文符号平均携带的信息量是 $1.4 \mathrm{bit} /$ 符号 $\left(H_{\infty} \cong 1.4 b i t\right)$, $<<5$ bit/符号,
等长编码效率极低, 如何提高效率? 如何体现有效性?



解决方法:
考察: 字母个数为 $\mathrm{q}$, 字母之间相关长度为 $\mathrm{N}$ 的英文信源, 其 可能的字母序列总数为 $q^N$; 但其中大部分字母序列是 无意义的字母组合, 而且随着 $N$ 的增加, 这种无意义 序列的总数越来越大。
方法: 进行联合编码, 即对字母序列编码, 且只对那些有意义的字 母序列编码, 即需编码的字母序列的总数 $<<q^N$, 则平均 每个信源符号所需的码符号个数可以大大减少, 从而提高了 传输效率。
问题: 会引入一定的误差：但当 $N$ 足够长后, 误差可以任意小。

---

得到提高编码效率的思路
（1）把离散无记忆的 $\mathrm{N}$ 次扩展信源划分成两个互补的集合 $A_{\varepsilon}$ 和 $\overline{A_{\varepsilon}}$ 。一个集合包含的都是经常出现的信源序列, 这个集合 出现的概率接近于1。另一个集合虽包含的元素较多, 但都不 是经常出现的信源序列, 总的出现的概率极小, 趋于零。
(2) 对高概率集 $A_{\varepsilon}$ 中的信源序列进行编码, 而将低概率集 $\overline{A_{\varepsilon}}$ 中的信源序列舍弃, 不编码。这样, 所需的平均码长可以减 少, 而所引起的错误概率却很小。
理论依据：渐进等分割性 (AEP)

引入渐进等分割性 (AEP) (详参见傅祖芸)
考察离散、随机序列信源的统计特性
——渐进等分割性 (AEP)
AEP描述: 渐进等分割定理 (熵定理, 遍历定理) 设 $s=s_1 s_2 \ldots s_N$ 是离散无记忆信源输出的一个特定序列, 则任给 $\varepsilon>0$ 和 $\delta>0$, 总可以找到一个整数 $N_0$, 使当 $N \geq N_0$ 时， 有:
$$
&P\left\{\left|\frac{\log P(s)}{-N}+H_{\infty}(S)\right|<\delta\right\}>1-\varepsilon\\
&\frac{\log P(s)}{N}——特定序列的平均符号自信息\\
&H_{\infty}(S)——随机矢量的平均符号熵
$$

## $\mathrm{AEP}$ 物理意义

任何一个离散随机序列信源当序列长度 $\mathrm{N} \rightarrow \propto$ 时, 信源序列会产 生两极分化: 大概率事件集合 $A_{\varepsilon}$ 与小概率事件集合 $A_{\varepsilon}$,

对于 $A_{\varepsilon}$ 有性质：
(1)
$$
\operatorname{Lim}_{N \rightarrow \infty} p\left(A_{\varepsilon}\right)=1
$$
(2) 信源熵趋近于大概率事件的熵
(3)
$$
\mathrm{P}_1=\cdots=\mathrm{P}_{\mathrm{M}_{\varepsilon}}=1 / \mathrm{M}_{\varepsilon}(等概率)
$$

对于 $\overline{A_{\varepsilon}}$ 有性质： 
$$
\lim_{N \rightarrow \infty} p\left(\overline{A_{\varepsilon}}\right)=0
$$
由此可见，信源编码只需对信源中少数落入典型大概率事件的集合的符号进行编码即可。而对大多数属于非典型小概率事件集合中的信源符号无需编码。

集合 $A_{\varepsilon}$ 和 $\overline{A_{\varepsilon}}$ 中的序列分别称为 $\varepsilon$ 典型序列和 $\varepsilon$ 非典型序列 

可以证明: 对于任意小的正数 $\delta \geq 0, \varepsilon \geq 0$, 当 $\mathrm{N}$ 足够大时,
$$
(1-\delta) 2^{N[H(S)-\varepsilon]} \leq\left\|A_{\varepsilon}\right\| \leq 2^{N[H(S)+\varepsilon]}
$$
$\left\|A_{\varepsilon}\right\|$ 表示 $\mathrm{S}^{\mathrm{N}}$ 中所有 $\varepsilon$ 典型序列的集合 $A_{\varepsilon}$ 中序列的个数

典型序列是那些平均自信息任意小地接近信源熵 的 N长序列的集合。

还可以证明: 对于任意小的正数 $\varepsilon \geq 0, \alpha_i \in A^{\prime} \mathrm{B}^{\prime} \mathrm{N}$ 足够大时
$$
2^{-N[H(S)+\varepsilon]} \leq p\left(\alpha_i\right) \leq 2^{-N[H(S)-\varepsilon]}
$$
$p\left(\alpha_i\right)$ 表示序列 $\alpha_i \in A_{\varepsilon}$ 出现的概率
由切比雪夫不等式可得: $p\left(A_{\varepsilon}\right) \geq 1-\frac{\sigma^2}{N \varepsilon^2}$
$\sigma^2$ 表示 $\mathrm{S}$ 中每个符号携带的信息量的方差
$$
\begin{aligned}
&\sigma^2=E^2\left\{\left[I\left(s_i\right)-E\left(I\left(s_i\right)\right)\right]\right\}=E\left[I^2\left(s_i\right)\right]-E^2\left[I\left(s_i\right)\right] \\
&=\sum p\left(s_i\right) I^2\left(s_i\right)-H^2(S)=\sum p\left(s_i\right)\left[-\log p\left(s_i\right)\right]^2-H^2(S)
\end{aligned}
$$
$\mathrm{AEP}$ 结论(当 $\mathrm{N}$ 足够大时)
- 所有 $\varepsilon$ 典型序列出现的概率近似相等, 即 $\varepsilon$ 典型序列为渐进 等概序列
- 可粗略认为 $\varepsilon$ 典型序列出现的概率为 $2^{-N H(S)}$
- 所有 $\boldsymbol{\varepsilon}$ 典型序列的概率和接近为 1 , 即 $p\left(A_{\varepsilon}\right)=1$
AEP应用:
- 提出、证明都是基于离散无记忆序列信源
- 平稳遍历信源有类似结果
- 体现信源统计特性
- 能用以证明定长编码定理

## 定长 (等长) 信源编码定理



一个熵为 $\mathrm{H}(\mathrm{S})$ 的离散无记忆平稳信源 $\mathrm{S}=\left(\mathrm{s}_1, \mathrm{~s}_2, \ldots, \mathrm{s}_{\mathrm{q}}\right)$, 若对 信源长为 $\mathrm{N}$ 的符号序列进行等长编码, 设码字从 $r$ 个字母的码 符号集 $\mathrm{X}=\left(x_1, x_2, \ldots, x_r\right)$ 中选取 $l$ 个码元组成, 对任意 $\varepsilon>0, \delta>0$,

编码前相当于对单符号信 源 $\mathrm{S}$ 进行N次扩展的多符号序列, 编码后相当对 $\mathrm{X}$ 的l次扩展的多称号序列

(1)正定理：只要 $\quad \frac{l}{N} \log r \geq H(S)+\varepsilon$
则当 $\mathrm{N}$ 足够大时, 可以实现几乎无失真编码, 即可使译码差错 小于 $\delta$,
(2)逆定理：当 $\frac{l}{N} \log r \leq H(S)-2 \varepsilon$
时, 不可能实现无失真编码, 而当 $\mathrm{N}$ 足够大时, 译码错误概率 近似等于 1 。
解释:定长编码定理给出了信源进行等长编码所需码长的理论极限值

定长编码定理几点说明:
$$
\frac{l}{N} \log r \geq H(S)+\varepsilon
$$
### 信息率 (编码速率)

$R=(l / N) \log _2 r \mathrm{bit} /$ 信源符号
$\log _2 r$ : 每个码符号的最大熵 (bit/码符号)
$l \log _2 r$ : 每个码符号序列最大熵 (bit/码序列)
$(l / N) \log _2 r$ : 编码后, 平均每个信源符号所能载荷的最大信息量

### 编码效率

$$
\eta=\frac{H(S)}{R}
$$
$H(S)$ 一编码前, 平均每个信源符号包含的信息量 $R$ ——编码后, 平均每个信源符号所能传送的最大信息量 若在正定理中取等号: $R=H(S)+\varepsilon$, 于是
$$
\eta=\frac{H(S)}{H(S)+\varepsilon}
$$

### (3)正定理指出

当信息率 $R>$ 单符号熵 $H(S)$ 时可做到几乎无失真译码, 条 件是 $N$ 足够大。
可以证明 只要 $N \geq \frac{\sigma^2(S)}{\varepsilon^2 \delta}$, 译码差错率必小于 $\delta$ $\sigma^2(S)$ ——信源序列自信息方差
$$
\begin{aligned}
&\sigma^2(S)=\sigma^2\left(I\left(s_i\right)\right)=E\left\{\left[I\left(s_i\right)-H(S)\right]^2\right\}=E\left[I^2\left(s_i\right)\right]-H^2(S) \\
&=\sum p\left(s_i\right)\left[-\log p\left(s_i\right)\right]^2-H^2(S)
\end{aligned}
$$

### (4) 逆定理指出

若 $R$ 比 $H(S)$ 小一个 $\varepsilon$ 时, 译码差错末必超过 $\delta$ 若 $R$ 比 $H(S)$ 小两个 $\varepsilon$ 时, 译码差错必定大于 $\delta$ $N \rightarrow \infty$ 时必失真

### (5) 结论

(单符号) 信源熵 $H(S)$ 实为一个界限
当 $R>H(S)$ 时 无失真译码
当 $R<H(S)$ 时 有失真译码

即只要码字传输的信息量大于信源序列携 带的信息量, 总可以实现几乎无失真编码

O 结论推广
- 可推广至离散、非平稳无记忆信源和有记忆信源（即 $\mathrm{H}(\mathrm{S})=\mathrm{H}_{\infty}(\mathrm{S})$ ) 情况。

### 定长编码定理证明(渐进等分割性)

$$
(1-\delta) 2^{N[H(S)-\varepsilon]} \leq\left\|A_{\varepsilon}\right\| \leq 2^{N[H(S)+\varepsilon]}
$$



- 将取自 $\mathrm{S}$, 长为 $\mathrm{N}$ 的信源符号序列分为集合 $\overline{A_{\varepsilon}}$ 和 $A_{\varepsilon}$
-只对集合 $A_{\varepsilon}$ 中的序列进行一一对应的等长编码
$$
\begin{aligned}
&r^l \geq\left\|A_{\varepsilon}\right\| \Rightarrow r^l \geq 2^{N[H(S)+\varepsilon]} \\
&l \log r \geq N[H(S)+\varepsilon]
\end{aligned}
$$
- 此时的误差为 $P_E=P\left(\overline{A_{\varepsilon}}\right)$, 计算误差 $\overline{P_e} \leq \frac{\sigma^2}{N \varepsilon^2}$
- 可见当 $N \rightarrow \infty$, 且 $(l / N) \log r \geq \mathrm{H}(\mathrm{S})+\varepsilon$ 时, $P_E \rightarrow 0$

### 定长编码定理 (实际应用问题)

编译码同步问题

- 问题: 如何使译码端知道码字起点
- 解决办法: 1、每个码字加短同步前缀
2、每若干码字加较长同步前缀
分组长度与编译码复杂性、编译码延时等等关系
- 问题: 要实现有效, 源序列分组很长, 使得编译码
复杂性和延时增加
- 解决办法: 目前没有理想到解决办法
。定长信源编码的理论意义远大于其实用价值。

---

例3.3: 设有一简单离散信源 $\left(\begin{array}{l}S \\ p(s)\end{array}\right)=\left[\begin{array}{l}s_1 s_2 \\ \frac{3}{4} \frac{1}{4}\end{array}\right]$ 对其进行近似于无失真的等长编码, 若要求其编码效率为 $96 \%$, 差错率低于 $10^{-5}$, 试求符号联合编码长度 $\mathrm{N}=$ ?

解: $H(S)=-\sum_{i=1}^2 p_i \log p_i=0.811(b i t /$ 信源符号 $)$
$$
\sigma^2=\sum_{i=1}^2 p_i\left(\log p_i\right)^2-[H(S)]^2=0.4715
$$
由编码效率: $\frac{H(S)}{H(S)+\varepsilon}=96 \%$

得 $\quad 0.811=0.811 \times 0.96+0.96 \varepsilon \Rightarrow \varepsilon \approx 0.034$

$\overline{P_{\varepsilon}} \leq \frac{\sigma^2}{N \varepsilon^2} \Rightarrow N \geq \frac{\sigma^2}{\varepsilon^2 \overline{P_{\varepsilon}}}=\frac{0.4715}{(0.034)^2 \times 10^{-5}} \cong 4.1 \times 10^7$

可见, 信源序列长度需要4100万个符号, 才能达到上述要 求, 这显然是不现实的.
结论: 定长编码简单, 但要达到一定的差错率不易实 现, 且编码效率低。

无失真信源编码实现方法一
$$
\left(\begin{array}{l}
S \\
p
\end{array}\right)=\left[\begin{array}{l}
s_1 s_2 \\
\frac{3}{4} \frac{1}{4}
\end{array}\right] \stackrel{\text { 改变信源 }}{\Longrightarrow}\left(\begin{array}{l}
S^N \\
p
\end{array}\right)=\left[\begin{array}{lllll}
\alpha_1 & \alpha_2 & \cdots & \alpha_n & \cdots \alpha_{n+m} \cdot \\
\frac{1}{n} & \frac{1}{n} & \cdots \frac{1}{n} & \cdots 0 & \cdots
\end{array}\right]
$$
??

无失真信源编码实现方法二
$$
\left(\begin{array}{l}
S \\
p
\end{array}\right)=\left[\begin{array}{ccc}
s_1 & s_2 & s_3 \\
\frac{3}{4} & \frac{1}{8} & \frac{1}{8}
\end{array}\right] \stackrel{\text { 适应信源 }}{=} \longrightarrow \text { 大概率→短码; 小概率 } \rightarrow \text { 长码 }\\
变长编码
\$$
\left(\begin{array}{l}
S \\
p \\
c
\end{array}\right)=\left[\begin{array}{ccc}
s_1 & s_2 & s_3 \\
\frac{3}{4} & \frac{1}{8} & \frac{1}{8} \\
0 & 10 & 11
\end{array}\right]
$$
$$
